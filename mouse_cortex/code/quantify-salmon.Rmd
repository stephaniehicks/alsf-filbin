---
title: quantification of mouse cortex data 
author: Stephanie Hicks and Albert Kuo
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{bash}
# Commands to start an interactive session on the JHPCE cluster
ii # alias for qrsh -l mem_free=20G,h_vmem=20G
module load conda_R
cd /fastscratch/myscratch/akuo/alsf-filbin
R
```

# Organize directory

```{r}
library(here)
```

First, we create the folder to store reference files (e.g. genome and cDNA) and quantification files (quantified counts) from salmon.  

```{r}
if(!dir.exists(here("salmon_files"))){
  dir.create(here("salmon_files"))
}
if(!dir.exists(here("salmon_files", "human"))){
  dir.create(here("salmon_files", "human"))
}
if(!dir.exists(here("salmon_files", "mouse"))){
  dir.create(here("salmon_files", "mouse"))
}
if(!dir.exists(here("mouse_cortex", "salmon_quants"))){
  dir.create(here("mouse_cortex", "salmon_quants"))
}
if(!dir.exists(here("mouse_cortex", "log"))){
  dir.create(here("mouse_cortex", "log"))
}
```

# Quantification 

We will do quantification with alevin from Salmon:

## Download files

We need to download 3 files (mouse):

1. `GRCm38.primary_assembly.genome.fa.gz` - nucleotide (DNA) sequences of the **GRCm38 primary genome assembly** (chromosomes and scaffolds -- i.e. unplaced scaffolds?)
2. `gencode.v32.transcripts.fa.gz` - nucleotide (DNA) sequences of **all transcripts** on reference chromosomes (Note: We are going to extract the transcript sequences using \#1 and \#3, so this will on longer be used.)
3. `gencode.v32.annotation.gtf.gz` - gene annotation on the reference chromosomes (i.e. for humans, these are chromosomes 1 to 22, X, and Y), i.e. locations of genes and other information about the genes, gene structure
  * Gene transfer format (GTF) is a file format used to hold information about gene structure. It is a tab-delimited text format based on the general feature format (GFF), but contains some additional conventions specific to gene information.

Source: https://www.gencodegenes.org/human/

```{r}
library(here)

# download GENCODE primary assembly fasta file
if(!file.exists(here("salmon_files", "mouse", "GRCm38.primary_assembly.genome.fa.gz"))){
  tar_gz_file <- "ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/GRCm38.primary_assembly.genome.fa.gz"
  download.file(tar_gz_file, 
                destfile = here("salmon_files", "mouse", "GRCm38.primary_assembly.genome.fa.gz"), 
                method = "wget")
}

# download GENCODE transcripts fasta file
if(!file.exists(here("salmon_files", "mouse", "gencode.vM25.transcripts.fa.gz"))){
  tar_gz_file <- "ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.transcripts.fa.gz"
  download.file(tar_gz_file,
                destfile = here("salmon_files", "mouse", "gencode.vM25.transcripts.fa.gz"),
                method = "wget")
}

# download GENCODE gtf file
if(!file.exists(here("salmon_files", "mouse", "gencode.vM25.annotation.gtf.gz"))){
  tar_gz_file <- "ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.annotation.gtf.gz"
  download.file(tar_gz_file, 
                destfile = here("salmon_files", "mouse", "gencode.vM25.annotation.gtf.gz"), 
                method = "wget")
}
```




## mRNA only ("transcripts") pipeline

```{r}
suppressPackageStartupMessages({
  library(here)
  library(dplyr)
  library(Biostrings)
  library(rtracklayer)
  library(GenomicFeatures)
  library(BSgenome)
})
# source(here("scripts", "quantify-salmon-helpers.R")) # cannot find this file in github -- need to ask Albert
```

### FASTA file

For the mRNA only index pipeline, we will build the transcripts FASTA using the transcripts GTF and the whole genome FASTA.

Note: We used to use the downloaded FASTA file from GENCODE. 
However, extracting the FASTA from the whole genome is more consistent with the other pipelines. 
In theory, they should be the same thing.


### tx2gene

We make a transcript-to-gene mapping table from the gtf file. 
This table will serve as the basis for similar tables in the other pipelines.

Source: README in https://github.com/csoneson/rna_velocity_quant

```{r}
suppressPackageStartupMessages({
  library(rtracklayer)
  library(dplyr)
  library(here)
})

# Read gtf
gtf <- rtracklayer::import(here("salmon_files", "mouse",
                                "gencode.vM25.annotation.gtf.gz")) 
gtftx <- subset(gtf, type == "transcript")
gtfex <- subset(gtf, type == "exon")

df <- data.frame(gtftx, stringsAsFactors = FALSE) %>%
  dplyr::select(transcript_id, seqnames, start, end, strand, source, 
                gene_id, gene_type, gene_name, level, havana_gene, transcript_type,
                transcript_name, transcript_support_level, tag, havana_transcript) %>%
  dplyr::left_join(data.frame(gtfex, stringsAsFactors = FALSE) %>%
                     dplyr::group_by(transcript_id) %>% 
                     dplyr::summarize(transcript_length = sum(width)),
                   by = "transcript_id")

# Write table as txt and rds
write.table(df %>% dplyr::select(transcript_id, gene_id), 
            file = here("salmon_files", "mouse", "gencode.v32.annotation.tx2gene.mouse.txt"), 
            sep = "\t", quote = FALSE, row.names = FALSE, 
            col.names = FALSE)
saveRDS(df, file = here("salmon_files", "mouse", "gencode.v32.annotation.tx2gene.mouse.rds"))
```

### decoys (only for Salmon)

The decoy sequence is going to be the whole genome sequence (`GRCm38.primary_assembly.genome.fa.gz`) for all 3 pipelines. You can read more about decoy sequences in Salmon below:

* https://salmon.readthedocs.io/en/latest/salmon.html#preparing-transcriptome-indices-mapping-based-mode
* https://github.com/COMBINE-lab/SalmonTools/blob/master/README.md

Source for code: https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/

To use a decoy, we need to create two files:

1. `decoys.txt` is the names of the genome targets (decoys), will be used in the `-d` parameter in `build-index-salmon.sh`
2. `gentrome_transcripts.fa.gz` is a concatenated FASTA transcriptome, will be used in the `-t` parameter in `build-index-salmon.sh`. Note that you need to recreate this in every pipeline.

```{bash}
# 1. Salmon indexing requires the names of the genome targets, which is extractable by using the grep command:
grep "^>" <(gunzip -c GRCm38.primary_assembly.genome.fa.gz) | cut -d " " -f 1 > decoys.txt
sed -i.bak -e 's/>//g' decoys.txt
```

```{bash}
# 2. Along with the list of decoys salmon also needs the concatenated transcriptome and genome reference file for index. NOTE: the genome targets (decoys) should come after the transcriptome targets in the reference
cat gencode.vM25.transcripts.fa.gz GRCm38.primary_assembly.genome.fa.gz > gentrome_transcripts.fa.gz
```

## mRNA and pre-mRNA ("preandmrna") pipeline

For the mRNA and pre-mRNA pipeline, we will build an index with both mRNA and pre-mRNA sequences. 

Source: generate_spliced_unspliced_fa.R in https://github.com/csoneson/rna_velocity_quant/.

```{r}
suppressPackageStartupMessages({
  library(here)
  library(dplyr)
  library(Biostrings)
  library(rtracklayer)
  library(GenomicFeatures)
  library(BSgenome)
})
source(here("mouse_cortex", "code", "quantify-salmon-helpers.R"))
```

### FASTA file 

We make a combined FASTA file with both mRNA and pre-mRNA sequences (`gencode.v32.preandmrna.fa`).

```{r}
# Gtf path
gtf_file <- here("salmon_files", "gencode.vM25.annotation.gtf.gz") # human file is gencode.v32.annotation.gtf.gz

# Read genomic (DNA) sequence from FASTA file
genome_fasta <- here("salmon_files", "GRCm38.primary_assembly.genome.fa.gz") # human file is GRCh38.primary_assembly.genome.fa.gz
genome <- Biostrings::readDNAStringSet(genome_fasta)
names(genome) <- sapply(strsplit(names(genome), " "), .subset, 1) # creates chr1, etc

# Extract transcript (tx) and pre-mRNA (premrna) sequences (takes a few minutes)
tx <- extractTxSeqs(gtf = gtf_file, genome = genome, type = "spliced")
premrna <- extractTxSeqs(gtf = gtf_file, genome = genome, type = "unspliced")
names(premrna) <- paste0(names(premrna), "_unspliced")

# Combine mRNA and pre-mRNA sequences
preandmrna <- c(tx, premrna)

# Write FASTA file (9 GB)
Biostrings::writeXStringSet(preandmrna, file = here("salmon_files", "gencode.v32.preandmrna.mouse.fa"))
```

### tx2gene

```{r}
# Generate tx2gene table for mRNA and pre-mRNA transcripts
t2g <- readRDS(here("salmon_files", "gencode.v32.annotation.tx2gene.mouse.rds"))
t2gpre <- t2g %>% dplyr::mutate(transcript_id = paste0(transcript_id, "_unspliced"))
t2g <- rbind(t2g, t2gpre)

# Write table as txt
write.table(t2g %>% dplyr::select(transcript_id, gene_id), 
            file = here("salmon_files", "gencode.v32.preandmrna.tx2gene.mouse.txt"), 
            row.names = FALSE, col.names = FALSE, 
            sep = "\t", quote = FALSE)
```

### decoys

1. `decoys.txt` was already generated in the mRNA only pipeline

2. `gentrome_preandmrna.fa.gz` is a concatenated FASTA transcriptome, will be used in the `-t` parameter in `build-index-salmon.sh`ls -

```{bash}
# The genome targets (decoys) should come after the transcriptome targets in the reference
gzip gencode.v32.preandmrna.mouse.fa # Note: This will take a while (~ 1 hour)
cat gencode.v32.preandmrna.mouse.fa.gz GRCm38.primary_assembly.genome.fa.gz > gentrome_preandmrna_mouse.fa.gz
```

## Run salmon alevin

### Install and build salmon index 

This part will have to be done for each user. 
I installed the salmon 1.2.1 binary in my home directory here `/users/shicks1/src/`. 

To install salmon v1.2.1: 
```{bash}
cd /users/shicks1/src/

wget https://github.com/COMBINE-lab/salmon/releases/download/v1.2.1/salmon-1.2.1_linux_x86_64.tar.gz
tar xzvf salmon-1.2.1_linux_x86_64.tar.gz
rm salmon-1.2.1_linux_x86_64.tar.gz
```

Also, make sure this is in the `.bash_profile` file
```{bash}
PATH=$PATH:/users/shicks1/src/salmon-latest_linux_x86_64/bin
```

You can check to make sure salmon has been upgraded correctly using `salmon -h` inside terminal (or help with specific parts of using salmon using e.g. `salmon index -h` for help with the index step). 

OK, we are ready to use salmon. 
The `-t` argument is the input transcripts file. 
The `-i` argument is the index file to create. 
The `-d` argument is the decoy sequence. 
The `--keepDuplicates` argument forces all duplicate transcripts (for example, multiple unspliced transcript of the same gene that are identical for example) that appear in the input will be retained and quantified separately. 
If you keep the duplicates they will be assigned identical expression levels since salmon can’t tell them apart. 
When you aggregate on the gene level, this will not make a difference any more. 
Therefore, I do not keep the duplicates as we are interested in gene level aggregation. 
The `--gencode` flag will handle the composite fasta headers in GENCODE transcript fasta files and split the transcript name at the first '|' character. 
The `--threads` argument says how many threads to use when building the index. 

There is a script `build-index-salmon.sh` in the `/mouse_cortex` folder that was used to run this code with 4 cores. The index is built from the combined FASTA file.

### Quantification with salmon alevin

We will now use the index created by `build-index-salmon.sh`.
See the `mouse_cortex/run-alevin.sh` file.

### Set up the tximeta package 

Next, we use the `tximeta` package to create a SummarizedExperiment object.
If we try to run `tximeta(coldata)`, that will fail because `tximeta` won't be able to detect automatically what the reference transcriptome is. 
So, here we create our own [linked transcriptome](https://bioconductor.org/packages/release/bioc/vignettes/tximeta/inst/doc/tximeta.html#linked_transcriptomes) from the combined GTF file.
This step is not necessary if your index was only the mRNA transcripts.

A `linkedTxome` records key information about the sources of the transcript FASTA files, and the location of the relevant GTF file. 
It also records the checksum of the transcriptome that was computed by Salmon during the index step.

```{r}
suppressPackageStartupMessages({
  library(tximeta)
})

# create linkedTranscriptome for mRNA (only) decoys pipeline
index_dir <- here("salmon_files", "mouse", "salmon_index_gentrome_decoys_k25")
fasta_path <-  here("salmon_files", "mouse", "gencode.vM25.transcripts.fa.gz")
gtf_path <-  here("salmon_files", "mouse", "gencode.vM25.annotation.gtf.gz") 

json_file <- here("salmon_files", "mouse", paste0(basename(index_dir), ".json"))
makeLinkedTxome(indexDir=index_dir,
                source="other", organism="mouse",
                release="other", genome="GRCm38",
                fasta=fasta_path, gtf=gtf_path,
                jsonFile=json_file) # this command will add the index to the cache automatically
```


## Create SummarizedExperiment object

We also need to use the linkedTxome object to use `tximeta` properly, i.e. `rowRanges(se)` won't be `NULL` and tximeta will be able to match the transcripts to the genes for us. **Note: still doesn't work**

```{r eval = F}
suppressPackageStartupMessages({
  library(tximeta)
  library(BiocFileCache)
  library(SummarizedExperiment)
})

# check if linkedTxome is already in the cache
bfcloc <- getTximetaBFC()
bfc <- BiocFileCache(bfcloc)
bfcinfo(bfc)

# if not, load linkedTxome json file
json_file <- here("salmon_files", "mouse", "salmon_index_gentrome_decoys_k25.json")
loadLinkedTxome(json_file)
```

```{r eval = F}
sampleid = "SRR9169228"
se <- tximeta(coldata = data.frame(names = sampleid,
                             files = here("mouse_cortex", "salmon_quants", 
                                          "alevin", "quants_mat.gz"),
                             stringsAsFactors = FALSE), 
              type = "alevin", 
              tx2gene = here("salmon_files", "mouse", 
                             "gencode.v32.annotation.tx2gene.mouse.txt"))

# Check SummarizedExperiment object
colData(se)
assayNames(se)
rowRanges(se)
```


### trying to fit Poisson-Gamma models with `glmGamPoi`
```{r}
library(glmGamPoi)
library(tidyverse)

non_empty_rows <- which(rowSums(assay(se, "counts")) > 1)
se_subset <- se[non_empty_rows, ]
se_subset
assay(se_subset, "counts") <- as.matrix(assay(se_subset, "counts"))

fit_pois <- glmGamPoi::glm_gp(se_subset, design = ~ 1, size_factors = FALSE, 
                         overdispersion = FALSE)
fit_pois
names(fit_pois)

tmp_pois <- data.frame("mean_fit" = rowMeans(fit_pois$Mu), 
           "variance_pois_fit" = rowMeans(fit_pois$Mu), 
           "variance_emp" = genefilter::rowVars(assay(se_subset, "counts"))) %>% 
  tidyr::pivot_longer(cols = -mean_fit, names_to = "var_type", values_to = "var_value")

tmp_pois %>%
  ggplot(aes(x = mean_fit, y = var_value, color = var_type)) + 
  geom_point() + 
  scale_x_log10() + scale_y_log10()




fit_nb <- glmGamPoi::glm_gp(se_subset, design = ~ 1, size_factors = FALSE, 
                         overdispersion = TRUE)
fit_nb
names(fit_nb)

tmp_nb <- data.frame("mean_fit" = rowMeans(fit_nb$Mu), 
           "variance_NB_fit" = rowMeans(fit_nb$Mu) + rowMeans(fit_nb$Mu)^2 * fit_nb$overdispersions, 
           "variance_emp" = genefilter::rowVars(assay(se_subset, "counts"))) %>% 
  tidyr::pivot_longer(cols = -mean_fit, names_to = "var_type", values_to = "var_value")

tmp_nb %>%
  ggplot(aes(x = mean_fit, y = var_value, color = var_type)) + 
  geom_point() + 
  scale_x_log10() + scale_y_log10()
```

