---
title: "download data from GEO"
author: "Albert Kuo"
date: "5/22/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Packages
library(here)
# BiocManager::install("GEOquery")
library(GEOquery)
library(tidyverse)
```

# Download data

Information about the paper whose data we are downloading:

* https://www.nature.com/articles/s41587-020-0465-8
* Systematic comparison of single-cell and single-nucleus RNA-sequencing methods
* Ding	2020
* Mouse cortex	~7000?
* UMIs and reads
* RNA-seq data generated in this project are available from the Gene Expression Omnibus with accession number **GSE132044** and the Single Cell Portal with accession numbers SCP424, SCP425 and SCP426. https://singlecell.broadinstitute.org/single_cell/study/SCP425/single-cell-comparison-cortex-data#study-summary


```{r}
gse <- GEOquery::getGEO("GSE132044")
sapply(gse, dim) # Number of rows per entry

gse2 <- gse[[2]]
pdata2 <- Biobase::pData(gse2) # Get phenotype table

pdata2 %>%
  select(title, organism_ch1, source_name_ch1, description, description.1, starts_with("characteristics")) %>% 
  head(n=6)
table(pdata2$description)
table(pdata2$source_name_ch1)
table(pdata2$organism_ch1)
table(pdata2$characteristics_ch1.3)

pdata2$Experiment <- sapply(stringr::str_split(pdata2$relation.1, "="), tail, 1)
```

1. human PBMC, scRNA-seq
2. mouse cortex, scRNA-seq (my guess is that this is a mislabeling, it should be single-nucleus)
3. human cell line and PBMC, bulk RNA-seq
4. mouse cell line and cortex, bulk RNA-seq
5. mixture of human and murine cell line, scRNA-seq


#### To download the `SRR` files

Go here: https://www.ncbi.nlm.nih.gov/bioproject/PRJNA545730. 
Then click on `SRA Experiments`. Click `Send to`. Choose `File`. 
Change Format to `RunInfo`. Click `Create File`. 

This will download a file called `SraRunInfo.csv`. Read this file in. 

```{r}
sra <- readr::read_csv(here("files", "SraRunInfo.csv"))
tmp <- left_join(pdata2, sra, by = "Experiment") # Only the second entry (mouse cortex)
write.table(tmp$Run, file = here("files", "SRR_files.txt"), 
            quote= FALSE,row.names = FALSE, col.names = FALSE)
```

#### To install the SRA tool kit

Two relevant pages to install SRA toolkit

1. https://www.ncbi.nlm.nih.gov/sra/docs/sradownload/
2. https://github.com/ncbi/sra-tools/wiki/05.-Toolkit-Configuration (old version is https://ncbi.github.io/sra-tools/install_config.html )

The second one is relevant on where you want the data downloaded as a default. 

```{bash}
cd src 
wget "http://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/current/sratoolkit.current-centos_linux64.tar.gz"
tar -xzf sratoolkit.current-centos_linux64.tar.gz
```

You will need to add the Toolkit functions to your PATH variable (https://github.com/ncbi/sra-tools/wiki/02.-Installing-SRA-Toolkit). This can be done by adding ~/.../sratoolkit.2.10.6-centos_linux64/bin to the PATH variable in ~/.bash_profile. Check that it worked with `which fastq-dump`.

To test that the toolkit is working:

```{bash}
prefetch SRR390728 
fastq-dump --stdout -X 2 SRR390728 # Note: They only included this line in the documentation, but it appears necessary to prefetch first
```

In theory, you can skip prefetch and use fasterq-dump by omitting the file extension .sra, but this does not work for their example SRR390728 for some reason. However, it works for the example SRR390728.

```{bash}
fasterq-dump --split-files SRR390728 
```


#### Download the `.sra` files

Following the 2nd link, I changed default location to download data to be at 
`/fastscratch/myscratch/shicks1`. 

Run the sh script `download-geo-data.sh`.

```{bash}
cd /fastscratch/myscratch/shicks1
prefetch SRR9169228
# or 
prefetch --option-file SRR_files.txt
```

where `SRR_files.txt` is defined above and the first few lines look like this: 

SRR9169228
SRR9169229
SRR9169230
SRR9169231

#### Extracting `.fastq` files

Finally, the the `fasterq-dump` function converts the prefetched `.sra` files
from compressed SRA format to fastq.

Run the sh script `convert-geo-data.sh`.

```{bash}
cd sra
fasterq-dump --split-files SRR9167437.sra
```

note you can also use the the gnu command `parallel` to parallelize this 
process. We specify the number of threads to send the individual 
commands to using the parameter `-j` and here we specify 25 threads. 

**Note:** you have to ask for these many cores with a `.sh` script. 

```{bash}
cat SRR_files.txt | parallel -j 25 fasterq-dump {}.sra 
```


