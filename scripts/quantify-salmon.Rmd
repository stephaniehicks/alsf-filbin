---
title: quantification of single nuc-seq data (alsf-filbin) with salmon 
author: Stephanie Hicks and Albert Kuo
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{bash}
# Commands to start an interactive session on the JHPCE cluster
ii # alias for qrsh -l mem_free=20G,h_vmem=20G
module load conda_R
cd /fastscratch/myscratch/akuo/alsf-filbin
R
```

# Organize directory

```{r}
library(here)
```

This code chunk copies the data from where it is stored into the github repo so we can all work with relative paths. 

```{r}
# stephanie_data_path <- "/users/shicks1/data/alsf_filbin/sample"
albert_data_path <- "/users/akuo/alsf-filbin/sample_data"

if(!dir.exists(here("sample_data"))){
  dir.create(here("sample_data"))
  
  # file.copy(stephanie_data_path, here("sample_data"), recursive=FALSE)
  file.copy(list.files(albert_data_path, full.names = TRUE), here("sample_data"), recursive=TRUE)
}

# verify the tumor files has been transferred. 
tumor_names <- list.files(here("sample_data"))[
                  !grepl("*.txt", list.files(here("sample_data")))]
print(tumor_names)
```

Next, we create the folder to store reference files (e.g. genome and cDNA) and quantification files (quantified counts) from salmon.  

```{r}
if(!dir.exists(here("salmon_files"))){
  dir.create(here("salmon_files"))
}

if(!dir.exists(here("salmon_quants"))){
  dir.create(here("salmon_quants"))
}
```

Create a list of paths for each cell which will be used when we quantify with salmon. 

```{r}
if(!file.exists(here("sample_data", "unique_cell_paths.txt"))){
  unique_cell_paths <- NULL
  for(tum in tumor_names){
    ids <- list.files(here("sample_data", tum))
    ids <- unique(stringr::str_sub(ids, end=-11))
    ids <- here("sample_data", tum, ids)
    unique_cell_paths <- c(unique_cell_paths, ids)
  }
  readr::write_lines(unique_cell_paths,
                     path = here("sample_data","unique_cell_paths.txt"))
}
```

# Quantification 

We will do quantification with Salmon:

> Selective alignment, enabled by the --validateMappings flag, is a major feature enhancement introduced in recent versions of salmon. When salmon is run with selective alignment, it adopts a considerably more sensitive scheme that we have developed for finding the potential mapping loci of a read, and score potential mapping loci using the chaining algorithm introdcued in minimap2 [5]. It scores and validates these mappings using the score-only, SIMD, dynamic programming algorithm of ksw2 [6]. Finally, we recommend using selective alignment with a decoy-aware transcriptome, to mitigate potential spurious mapping of reads that actually arise from some unannotated genomic locus that is sequence-similar to an annotated transcriptome.

## Download files

We need to download 3 files:

1. `GRCh38.primary_assembly.genome.fa.gz` - nucleotide (DNA) sequences of the **GRCH38 primary genome assembly** (chromosomes and scaffolds -- i.e. unplaced scaffolds?)
2. `gencode.v32.transcripts.fa.gz` - nucleotide (DNA) sequences of **all transcripts** on reference chromosomes (Note: We are going to extract the transcript sequences using \#1 and \#3, so this will on longer be used.)
3. `gencode.v32.annotation.gtf.gz` - gene annotation on the reference chromosomes (i.e. for humans, these are chromosomes 1 to 22, X, and Y), i.e. locations of genes and other information about the genes, gene structure
  * Gene transfer format (GTF) is a file format used to hold information about gene structure. It is a tab-delimited text format based on the general feature format (GFF), but contains some additional conventions specific to gene information.

Source: https://www.gencodegenes.org/human/

```{r}
library(here)

# download GENCODE primary assembly fasta file
if(!file.exists(here("salmon_files", "GRCh38.primary_assembly.genome.fa.gz"))){
  tar_gz_file <- "ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_32/GRCh38.primary_assembly.genome.fa.gz"
  download.file(tar_gz_file, 
                destfile = here("salmon_files", "GRCh38.primary_assembly.genome.fa.gz"), 
                method = "wget")
}

# download GENCODE transcripts fasta file
# if(!file.exists(here("salmon_files", "gencode.v32.transcripts.fa.gz"))){
#   tar_gz_file <- "ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_32/gencode.v32.transcripts.fa.gz"
#   download.file(tar_gz_file, 
#                 destfile = here("salmon_files", "gencode.v32.transcripts.fa.gz"), 
#                 method = "wget")
# }

# download GENCODE gtf file
if(!file.exists(here("salmon_files", "gencode.v32.annotation.gtf.gz"))){
  tar_gz_file <- "ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_32/gencode.v32.annotation.gtf.gz"
  download.file(tar_gz_file, 
                destfile = here("salmon_files", "gencode.v32.annotation.gtf.gz"), 
                method = "wget")
}


## Mouse cortex equivalents
# download GENCODE primary assembly fasta file
if(!file.exists(here("salmon_files", "GRCm38.primary_assembly.genome.fa.gz"))){
  tar_gz_file <- "ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/GRCm38.primary_assembly.genome.fa.gz"
  download.file(tar_gz_file, 
                destfile = here("salmon_files", "GRCm38.primary_assembly.genome.fa.gz"), 
                method = "wget")
}

# download GENCODE gtf file
if(!file.exists(here("salmon_files", "gencode.vM25.annotation.gtf.gz"))){
  tar_gz_file <- "ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.annotation.gtf.gz"
  download.file(tar_gz_file, 
                destfile = here("salmon_files", "gencode.vM25.annotation.gtf.gz"), 
                method = "wget")
}
```

## mRNA only ("transcripts") pipeline

```{r}
suppressPackageStartupMessages({
  library(here)
  library(dplyr)
  library(Biostrings)
  library(rtracklayer)
  library(GenomicFeatures)
  library(BSgenome)
})
source(here("scripts", "quantify-salmon-helpers.R"))
```

### FASTA file

For the mRNA only index pipeline, we will build the transcripts FASTA using the transcripts GTF and the whole genome FASTA.

Note: We used to use the downloaded FASTA file from GENCODE. However, extracting the FASTA from the whole genome is more consistent with the other pipelines. In theory, they should be the same thing.

```{r}
# Gtf path
gtf_file <- here("salmon_files", "gencode.vM25.annotation.gtf.gz") # human file is gencode.v32.annotation.gtf.gz

# Read genomic (DNA) sequence from FASTA file
genome_fasta <- here("salmon_files", "GRCm38.primary_assembly.genome.fa.gz") # human file is GRCh38.primary_assembly.genome.fa.gz
genome <- Biostrings::readDNAStringSet(genome_fasta)
names(genome) <- sapply(strsplit(names(genome), " "), .subset, 1) # creates chr1, etc

# Extract transcript (tx) sequences 
tx <- extractTxSeqs(gtf = gtf_file, genome = genome, type = "spliced")

# Write FASTA file
Biostrings::writeXStringSet(tx, file = here("salmon_files", "gencode.v32.transcripts.mouse.fa"))
```

### tx2gene

We make a transcript-to-gene mapping table from the gtf file. This table will serve as the basis for similar tables in the other pipelines.

Source: README in https://github.com/csoneson/rna_velocity_quant

```{r}
suppressPackageStartupMessages({
  library(rtracklayer)
  library(dplyr)
  library(here)
})

# Read gtf
gtf <- rtracklayer::import(here("salmon_files", "gencode.vM25.annotation.gtf.gz")) # human file is gencode.v32.annotation.gtf.gz
gtftx <- subset(gtf, type == "transcript")
gtfex <- subset(gtf, type == "exon")

df <- data.frame(gtftx, stringsAsFactors = FALSE) %>%
  dplyr::select(transcript_id, seqnames, start, end, strand, source, 
                gene_id, gene_type, gene_name, level, havana_gene, transcript_type,
                transcript_name, transcript_support_level, tag, havana_transcript) %>%
  dplyr::left_join(data.frame(gtfex, stringsAsFactors = FALSE) %>%
                     dplyr::group_by(transcript_id) %>% 
                     dplyr::summarize(transcript_length = sum(width)),
                   by = "transcript_id")

# Write table as txt and rds
write.table(df %>% dplyr::select(transcript_id, gene_id), file = here("salmon_files", "gencode.v32.annotation.tx2gene.mouse.txt"), 
            sep = "\t", quote = FALSE, row.names = FALSE, 
            col.names = FALSE)
saveRDS(df, file = here("salmon_files", "gencode.v32.annotation.tx2gene.mouse.rds"))
```

### decoys

The decoy sequence is going to be the whole genome sequence (`GRCh38.primary_assembly.genome.fa.gz`) for all 3 pipelines. You can read more about decoy sequences in Salmon below:

* https://salmon.readthedocs.io/en/latest/salmon.html#preparing-transcriptome-indices-mapping-based-mode
* https://github.com/COMBINE-lab/SalmonTools/blob/master/README.md

Source for code: https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/

To use a decoy, we need to create two files:

1. `decoys.txt` is the names of the genome targets (decoys), will be used in the `-d` parameter in `build-index-salmon.sh`
2. `gentrome_transcripts.fa.gz` is a concatenated FASTA transcriptome, will be used in the `-t` parameter in `build-index-salmon.sh`. Note that you need to recreate this in every pipeline.

```{bash}
# 1. Salmon indexing requires the names of the genome targets, which is extractable by using the grep command:
grep "^>" <(gunzip -c GRCm38.primary_assembly.genome.fa.gz) | cut -d " " -f 1 > decoys_mouse.txt
sed -i.bak -e 's/>//g' decoys_mouse.txt
```

```{bash}
# 2. Along with the list of decoys salmon also needs the concatenated transcriptome and genome reference file for index. NOTE: the genome targets (decoys) should come after the transcriptome targets in the reference
gzip gencode.v32.transcripts.mouse.fa
cat gencode.v32.transcripts.mouse.fa.gz GRCm38.primary_assembly.genome.fa.gz > gentrome_transcripts_mouse.fa.gz
```

## mRNA and pre-mRNA ("preandmrna") pipeline

For the mRNA and pre-mRNA pipeline, we will build an index with both mRNA and pre-mRNA sequences. 

Source: generate_spliced_unspliced_fa.R in https://github.com/csoneson/rna_velocity_quant/.

```{r}
suppressPackageStartupMessages({
  library(here)
  library(dplyr)
  library(Biostrings)
  library(rtracklayer)
  library(GenomicFeatures)
  library(BSgenome)
})
source(here("scripts", "quantify-salmon-helpers.R"))
```

### FASTA file 

We make a combined FASTA file with both mRNA and pre-mRNA sequences (`gencode.v32.preandmrna.fa`).

```{r}
# Gtf path
gtf_file <- here("salmon_files", "gencode.v32.annotation.gtf.gz")

# Read genomic (DNA) sequence from FASTA file
genome_fasta <- here("salmon_files", "GRCh38.primary_assembly.genome.fa.gz")
genome <- Biostrings::readDNAStringSet(genome_fasta)
names(genome) <- sapply(strsplit(names(genome), " "), .subset, 1) # creates chr1, etc

# Extract transcript (tx) and pre-mRNA (premrna) sequences (takes a few minutes)
tx <- extractTxSeqs(gtf = gtf_file, genome = genome, type = "spliced")
premrna <- extractTxSeqs(gtf = gtf_file, genome = genome, type = "unspliced")
names(premrna) <- paste0(names(premrna), "_unspliced")

# Combine mRNA and pre-mRNA sequences
preandmrna <- c(tx, premrna)

# Write FASTA file (9 GB)
Biostrings::writeXStringSet(preandmrna, file = here("salmon_files", "gencode.v32.preandmrna.fa"))
```

### tx2gene

```{r}
# Generate tx2gene table for mRNA and pre-mRNA transcripts
t2g <- readRDS(here("salmon_files", "gencode.v32.annotation.tx2gene.rds"))
t2gpre <- t2g %>% dplyr::mutate(transcript_id = paste0(transcript_id, "_unspliced"))
t2g <- rbind(t2g, t2gpre)

# Write table as txt
write.table(t2g, 
            file = here("salmon_files", "gencode.v32.preandmrna.tx2gene.txt"), 
            row.names = FALSE, col.names = FALSE, 
            sep = "\t", quote = FALSE)
```

### decoys

1. `decoys.txt` was already generated in the mRNA only pipeline

2. `gentrome_preandmrna.fa.gz` is a concatenated FASTA transcriptome, will be used in the `-t` parameter in `build-index-salmon.sh`ls -

```{bash}
# The genome targets (decoys) should come after the transcriptome targets in the reference
gzip gencode.v32.preandmrna.fa # Note: This will take a while (~ 1 hour)
cat gencode.v32.preandmrna.fa.gz GRCh38.primary_assembly.genome.fa.gz > gentrome_preandmrna.fa.gz
```

### old code
#### FASTA file

Now, for each entry in `grrange`, we extract the sequence from the corresponding `seqnames` entry in the `genome`.

**Note**: If you use Ensembl, there will be a discrepancy between the transcripts (e.g. ENST00000456328 vs ENST00000456328.1). 
Technically, it doesn't matter this point, but it will when we merge with the spliced (mRNA) transcripts.
So, if you do this, you will likely need to remove the version numbers before merging the pre-mRNA and mRNA fasta files. 
Or just use the Gencode annotation where the naming is consistent between the transcriptome fasta and the gtf.

```{r}
## Get genomic (DNA) sequence from FASTA file
genomefasta <- here("salmon_files", "GRCh38.primary_assembly.genome.fa.gz")

## Import FASTA file (DNA) with Biostrings::readDNAStringSet
genome <- Biostrings::readDNAStringSet(genomefasta)
names(genome) <- sapply(strsplit(names(genome), " "), .subset, 1) # creates chr1, etc

## Get the sequence of each pre-mRNA molecule
premrnaseq <- BSgenome::getSeq(x = genome, names = grrange)

## Save pre-mRNA sequences to fasta file 
premrna_fasta <- here("salmon_files", "GRCh38.premRNA.fa")
Biostrings::writeXStringSet(premrnaseq, filepath = premrna_fasta)
```

Let's check to make sure the pre-mRNA and the mRNA have the same number of transcripts.

```{bash}
cd /fastscratch/myscratch/shicks1/alsf-filbin/salmon_files
# cd /fastscratch/myscratch/akuo/alsf-filbin/salmon_files
zcat gencode.v32.transcripts.fa.gz | grep ">"  | wc -l # mRNA
grep ">" GRCh38.premRNA.fa | wc -l                     # pre-mRNA
```

Both have the same number of rows (or transcripts): 227462.
I think it's also interesting that one is almost 6GB and the other is 70M. 

Now we will put the pre-mRNA (`GRCh38.premRNA.fa`) and mRNA (`gencode.v32.transcripts.fa.gz`) fasta GENCODE files together. 

```{bash}
cd /fastscratch/myscratch/shicks1/alsf-filbin/salmon_files
# cd /fastscratch/myscratch/akuo/alsf-filbin/salmon_files
zcat gencode.v32.transcripts.fa.gz > gencode.v32.transcripts.fa
cat GRCh38.premRNA.fa gencode.v32.transcripts.fa > gencode.v32.preandmrna.fa
grep ">" gencode.v32.preandmrna.fa | wc -l
```

Ok there are 454924 (or = 227462*2) transcripts, as we expect. Now let's zip this file up. 
This takes a while (~30-40 mins). 

```{bash}
cd /fastscratch/myscratch/shicks1/alsf-filbin/salmon_files
# cd /fastscratch/myscratch/akuo/alsf-filbin/salmon_files
gzip gencode.v32.preandmrna.fa

# gzip the pre-mRNA only
gzip GRCh38.premRNA.fa
```


#### GTF file

First, make a pre-mRNA GTF file (using the mRNA GTF file). Then combine it with the mRNA GTF file to get a GTF file for both pre-mRNA and mRNA.

```{r}
## Read gtf file and group exons by transcript
ingtf <- here("salmon_files","gencode.v32.annotation.gtf.gz")
txdb <- GenomicFeatures::makeTxDbFromGFF(ingtf)
grl <- GenomicFeatures::exonsBy(txdb, by = "tx", use.names = TRUE)

## Create the pre-mRNA coordinates by adding all introns to each transcript
grrange <- unlist(range(grl)) # 227462 rows
names(grrange) <- paste(names(grrange), "premrna", sep= ".")

## Save pre-mRNA gtf file
premrna_gtf <- here("salmon_files","gencode.v32.premrnaannotation.gtf")
rtracklayer::export(grrange, premrna_gtf)

## Combine two gtf files (pre-mRNA and mRNA) to be used in tximeta a bit later
unlist(grl) # 1372308 rows
tmp <- c(grrange, unlist(grl)) # 1599770 rows, pre-mRNA comes in front of mRNA

## example of a transcript with three exons (mRNA) or entire pre-mRNA region
tmp[grep("ENST00000456328.2", names(tmp)),]

## Save combined pre-mRNA and mRNA gtf file
preandmrna_gtf <- here("salmon_files","gencode.v32.preandmrnaannotation.gtf")
rtracklayer::export(tmp, preandmrna_gtf)
```


## mRNA and intron ("intronandmrna") pipeline

```{r}
# Modified from https://github.com/csoneson/rna_velocity_quant/blob/master/scripts/extractIntronSeqs.R
#' Extract intron sequences
#'
#' @param gtf The path to a gtf file
#' @param genome A \code{DNAStringSet} object with the genome sequence
#' @param type Either 'collapse' or 'separate'
#' @param flanklength The length of the exonic flanking sequence
#' @param joinOverlappingIntrons Whether overlapping intron sequences (after adding 
#'   the flanking sequence) should be joined into a single intron
#'
#' @return A \code{DNAStringSet} object with intronic sequences
#' 
extractIntronSeqs <- function(gtf, genome, type = "collapse", flanklength = 90,
                              joinOverlappingIntrons = FALSE) {
  ## Construct TxDb from gtf file
  txdb <- GenomicFeatures::makeTxDbFromGFF(gtf, format = "gtf")

  if (type == "separate") {
    ## Group exons by transcript
    grl <- GenomicFeatures::exonsBy(txdb, by = "tx", use.names = TRUE)
  } else if (type == "collapse") {
    ## Group exons by gene
    grl <- GenomicFeatures::exonsBy(txdb, by = "gene")

    ## Collapse the exons of each gene
    grl <- GenomicRanges::reduce(grl)
  } else {
    stop("Unknown 'type' argument")
  }

  ## Get introns as the set difference between the range and the exons,
  ## for each transcript/gene
  ## Here, the order of the introns doesn't really matter, since they
  ## will be considered separately (not joined together into a transcript)
  grl <- BiocGenerics::setdiff(range(grl), grl)

  ## Add flanking region
  grl <- grl + flanklength

  if (joinOverlappingIntrons) {
    ## If two (introns + flanklength) overlap, join them
    grl <- GenomicRanges::reduce(grl)
  }
  
  gr <- unlist(grl)

  ## Add -I{X} to names
  names(gr) <- gsub("\\-I\\.", "-I", make.unique(paste0(names(gr), "-I")))

  ## Get sequence
  gs <- BSgenome::getSeq(x = genome, names = gr)
  
  ## Manually set names of extracted sequences
  stopifnot(all(width(gs) == width(gr)))
  names(gs) <- names(gr)
  
  return(list(gs = gs, # will be written into fasta file
              gr = gr))# will be written into gtf file
}
```

```{r}
ingtf <- here("salmon_files","gencode.v32.annotation.gtf.gz")
genomefasta <- here("salmon_files", "GRCh38.primary_assembly.genome.fa.gz")
genome <- Biostrings::readDNAStringSet(genomefasta)
names(genome) <- sapply(strsplit(names(genome), " "), .subset, 1)

# Get intron sequence and gtf
intronseq <- extractIntronSeqs(gtf = ingtf, genome = genome, 
                  type = "collapse", flanklength = 90,
                  joinOverlappingIntrons = FALSE)

# Save intron sequences to fasta file
intron_fasta <- here("salmon_files", "GRCh38.intron.fa")
Biostrings::writeXStringSet(intronseq$gs, filepath = intron_fasta)

# Save intron gtf file
intron_gtf <- here("salmon_files","gencode.v32.intronannotation.gtf")
rtracklayer::export(intronseq$gr, intron_gtf)
```

Now we also want to generate an intron + mrna gtf and FASTA file.

```{r}
# Read gtf file and group exons by transcript
txdb <- GenomicFeatures::makeTxDbFromGFF(ingtf)
grl <- GenomicFeatures::exonsBy(txdb, by = "tx", use.names = TRUE)

# Combine gtf
tmp <- c(intronseq$gr, unlist(grl)) # length = c(288455, 1372308) under default parameters for intronseq

# Save combined intron and mRNA gtf file
intronandmrna_gtf <- here("salmon_files","gencode.v32.intronandmrnaannotation.gtf")
rtracklayer::export(tmp, intronandmrna_gtf)
```

```{bash}
# Cat FASTA files together
cd /fastscratch/myscratch/akuo/alsf-filbin/salmon_files
zcat gencode.v32.transcripts.fa.gz > gencode.v32.transcripts.fa
cat GRCh38.intron.fa gencode.v32.transcripts.fa > gencode.v32.intronandmrna.fa
```

```{bash}
# gzip the intron fasta
gzip GRCh38.intron.fa

# gzip the intron + mRNA fasta
gzip gencode.v32.intronandmrna.fa
```



## Install and build salmon index 

This part will have to be done for each user. 
I installed the salmon 1.0.0 binary in my home directory here `/users/shicks1/src/`. 

To install salmon v1.0.0: 
```{bash}
cd /users/shicks1/src/

wget https://github.com/COMBINE-lab/salmon/releases/download/v1.0.0/salmon-1.0.0_linux_x86_64.tar.gz
tar xzvf salmon-1.0.0_linux_x86_64.tar.gz
rm salmon-1.0.0_linux_x86_64.tar.gz
```

Also, make sure this is in the `.bash_profile` file
```{bash}
PATH=$PATH:/users/shicks1/src/salmon-latest_linux_x86_64/bin
```

You can check to make sure salmon has been upgraded correctly using `salmon -h` inside terminal (or help with specific parts of using salmon using e.g. `salmon index -h` for help with the index step). 

OK, we are ready to use salmon. 
The `-t` argument is the input transcripts file. 
The `-i` argument is the index file to create. 
The `-d` argument is the decoy sequence. 
The `--keepDuplicates` argument forces all duplicate transcripts (for example, multiple unspliced transcript of the same gene that are identical for example) that appear in the input will be retained and quantified separately. 
If you keep the duplicates they will be assigned identical expression levels since salmon can’t tell them apart. 
When you aggregate on the gene level, this will not make a difference any more. 
Therefore, I do not keep the duplicates as we are interested in gene level aggregation. 
The `--gencode` flag will handle the composite fasta headers in GENCODE transcript fasta files and split the transcript name at the first '|' character. 
The `--threads` argument says how many threads to use when building the index. 

There is a script `build-index-salmon.sh` in the `/scripts` folder that was used to run this code with 4 cores. The index is built from the combined FASTA file.

## Run salmon 

We will now use the index created by `build-index-salmon.sh`.
See the `scripts/run-salmon.sh` file or the `scripts/run-salmon-parallel.sh` file in the terminal. They do the same thing, but the latter will run salmon in parallel and be much faster.

## Set up the tximeta package 

Next, we use the `tximeta` package to create a SummarizedExperiment object.
If we try to run `tximeta(coldata)`, that will fail because `tximeta` won't be able to detect automatically what the reference transcriptome is. 
So, here we create our own [linked transcriptome](https://bioconductor.org/packages/release/bioc/vignettes/tximeta/inst/doc/tximeta.html#linked_transcriptomes) from the combined GTF file.
This step is not necessary if your index was only the mRNA transcripts.

A `linkedTxome` records key information about the sources of the transcript FASTA files, and the location of the relevant GTF file. 
It also records the checksum of the transcriptome that was computed by Salmon during the index step.

```{r}
suppressPackageStartupMessages({
  library(tximeta)
})

# create linkedTranscriptome for combined list of pre-mRNA and mRNA
index_dir <- here("salmon_files", "gencode.v32_salmon-index-v1.0.0")
fasta_path <-  here("salmon_files", "gencode.v32.preandmrna.fa.gz")
gtf_path <-  here("salmon_files", "gencode.v32.preandmrnaaannotation.gtf") 

# create linkedTranscriptome for pre-mRNA only
index_dir <- here("salmon_files", "gencode.v32_salmon-index-v1.0.0-premRNA")
fasta_path <-  here("salmon_files", "GRCh38.premRNA.fa.gz")
gtf_path <-  here("salmon_files", "gencode.v32.premrnaannotation.gtf") 

json_file <- here("salmon_files", paste0(basename(index_dir), ".json"))
makeLinkedTxome(indexDir=index_dir,
                source="other", organism="Homo sapiens",
                release="other", genome="GRCh38",
                fasta=fasta_path, gtf=gtf_path,
                jsonFile=json_file) # this command will add the index to the cache automatically
```


