---
title: quantification of single nuc-seq data (alsf-filbin) with salmon 
author: Stephanie Hicks
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(here)
```

This code chunk copies the data from where it is stored into the github repo so we can all work with relative paths. 
I copy it so I can keep the backed up copy where I originally have it. 
However, the person using this script needs to adjust which paths to use. 
```{r}
stephanie_data_path <- "/users/shicks1/data/alsf_filbin/sample"
# albert_data_dath <- "/users/akuo/data/alsf_filbin/sample"

if(!dir.exists(here("sample_data"))){
  dir.create(here("sample_data"))
  
  file.copy(stephanie_data_path, here("sample_data"), recursive=FALSE)
  # file.copy(albert_data_path, here("sample_data"), recursive=FALSE)
}

# verify the tumor files has been transferred. 
tumor_names <- list.files(here("sample_data"))[
                  !grepl("*.txt", list.files(here("sample_data")))]
```

Next, we create the folder to store reference files (e.g. genome and cDNA) and quantification files (quantified counts) from salmon.  
```{r}
if(!dir.exists(here("salmon_files"))){
  dir.create(here("salmon_files"))
}

if(!dir.exists(here("salmon_quants"))){
  dir.create(here("salmon_quants"))
}
```

List cells and tumor names 

```{r}
if(!file.exists(here("sample_data", "unique_cell_names.txt"))){
  unique_cell_names <- NULL
  for(tum in tumor_names){
    ids <- list.files(here("sample_data", tum))
    ids <- unique(stringr::str_sub(ids, end=-11))
    ids <- file.path(tum, ids)
    unique_cell_names <- c(unique_cell_names, ids)
  }
  readr::write_lines(unique_cell_names,
                     path = here("sample_data","unique_cell_filenames.txt"))
}
```

# Quantification 

## Download files needed for Salmon

Gene transfer format (GTF) is a file format used to hold information about gene structure. 
It is a tab-delimited text format based on the general feature format (GFF), but contains some additional conventions specific to gene information.

```{r}
# download GENCODE fastq DNA file 
if(!file.exists(here("salmon_files", "GRCh38.primary_assembly.genome.fa.gz"))){
  tar_gz_file <- "ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_32/GRCh38.primary_assembly.genome.fa.gz"
  download.file(tar_gz_file, 
                destfile = here("salmon_files", "GRCh38.primary_assembly.genome.fa.gz"), 
                method = "wget")
}

# download ensemble fastq cdna file 
if(!file.exists(here("salmon_files", "gencode.v32.transcripts.fa.gz"))){
  tar_gz_file <- "ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_32/gencode.v32.transcripts.fa.gz"
  download.file(tar_gz_file, 
                destfile = here("salmon_files", "gencode.v32.transcripts.fa.gz"), 
                method = "wget")
}

# download GENCODE gtf file 
if(!file.exists(here("salmon_files", "gencode.v32.annotation.gtf.gz"))){
  tar_gz_file <- "ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_32/gencode.v32.annotation.gtf.gz"
  download.file(tar_gz_file, 
                destfile = here("salmon_files", "gencode.v32.annotation.gtf.gz"), 
                method = "wget")
}
```

Next, we need to create a set of pre-mRNA sequences to save to a FASTA file. 
This is needed because we have single nucleus RNA-seq data so we need to take into account the pre-mRNA and mRNA transcripts. 
This code kindly comes from [Charlotte Soneson](https://csoneson.github.io).

```{r}
suppressPackageStartupMessages({
  library(Biostrings)
  library(rtracklayer)
  library(GenomicFeatures)
  library(BSgenome)
})

## Get genomic (DNA) sequence
genomefasta <- here("salmon_files", "GRCh38.primary_assembly.genome.fa.gz")

## Import FASTA file (DNA) with Biostrings::readDNAStringSet
genome <- Biostrings::readDNAStringSet(genomefasta)
names(genome) <- sapply(strsplit(names(genome), " "), .subset, 1) # creates chr1, etc

ingtf <- here("salmon_files","gencode.v32.annotation.gtf.gz")

## Read gtf file and group exons by transcript
txdb <- GenomicFeatures::makeTxDbFromGFF(ingtf)
grl <- GenomicFeatures::exonsBy(txdb, by = "tx", use.names = TRUE)

## Create the pre-mRNA coordinates by adding all introns to each transcript
grrange <- unlist(range(grl))
```

Now, for each entry in `grrange`, we extract the sequence from the corresponding `seqnames` entry in the `genome`. 

**Note**: If you use Ensembl, there will be a discrepancy between the transcripts (e.g. ENST00000456328 vs ENST00000456328.1). 
Technically, it doesn't matter this point, but it will when we merge with the spliced (mRNA) transcripts.
So, if you do this, you will likely need to remove the version numbers before merging the pre-mRNA and mRNA fasta files. 
Or just use the Gencode annotation where the naming is consistent between the transcriptome fasta and the gtf.

```{r}
## Get the sequence of each pre-mRNA molecule
premrnaseq <- BSgenome::getSeq(x = genome, names = grrange)

premrna_fasta <- here("salmon_files", "GRCh38.premRNA.fa")

## Save pre-mRNA sequences to fasta file 
Biostrings::writeXStringSet(premrnaseq, filepath = premrna_fasta)
```

Let's first check to make sure they have the same number of transcripts (pre-mRNA and mRNA). 
```{bash}
cd /fastscratch/myscratch/shicks1/alsf-filbin/salmon_files
zcat gencode.v32.transcripts.fa.gz | grep ">"  | wc -l
grep ">" GRCh38.premRNA.fa | wc -l
```

Both have the same number of rows (or transcripts): 227462.
I think it's also interesting that one is almost 6GB and the other is 70M. 

Now we will put the pre-mRNA (`GRCh38.premRNA.fa`) and mRNA (`gencode.v32.transcripts.fa.gz`) fasta GENCODE files together. 

```{bash}
cd /fastscratch/myscratch/shicks1/alsf-filbin/salmon_files
zcat gencode.v32.transcripts.fa.gz > gencode.v32.transcripts.fa
cat gencode.v32.transcripts.fa GRCh38.premRNA.fa > gencode.v32.preandmrna.fa
grep ">" gencode.v32.preandmrna.fa | wc -l
```

Ok there are 454924 (or = 227462/2) transcripts, as we expect. Now let's zip this file up. 
This takes a while. 

```{bash}
gzip gencode.v32.preandmrna.fa
```

And clean up our space 
```{bash}
rm gencode.v32.transcripts.fa
rm gencode.v32.transcripts.fa.gz
rm GRCh38.premRNA.fa
```

## Install and build salmon index 

This part will have be done for each user. 
I installed the salmon 1.0.0 binary in my home directory here `/users/shicks1/src/`. 

To install salmon v1.0.0: 
```{bash}
cd /users/shicks1/src/

wget https://github.com/COMBINE-lab/salmon/releases/download/v1.0.0/salmon-1.0.0_linux_x86_64.tar.gz
tar xzvf salmon-1.0.0_linux_x86_64.tar.gz
rm salmon-1.0.0_linux_x86_64.tar.gz
```

Also, make sure this is in the `.bash_profile` file
```{bash}
PATH=$PATH:/users/shicks1/src/salmon-latest_linux_x86_64/bin
```

You can check to make sure salmon has been upgraded correctly using `salmon -h` inside terminal (or help with specific parts of using salmon using e.g. `salmon index -h` for help with the index step). 

OK, we are ready to use salmon. 
The `-t` argument is the input transcripts file. 
The `-i` argument is the index file to create. 
The `--keepDuplicates` argument forces all duplicate transcripts (for example, multiple unspliced transcript of the same gene that are identical for example) that appear in the input will be retained and quantified separately. 
If you keep the duplicates they will be assigned identical expression levels since salmon canâ€™t tell them apart. 
When you aggregate on the gene level, this will not make a difference any more. 
Therefore, I do not keep the duplicates as we are interested in gene level aggregation. 
The `--threads` argument says how many threads to use when building the index. 

There is a script `build-index-salmon.sh` in the `/scripts` folder that was used to run this code with 4 cores.
But I put it here too. 

```{bash}
cd /fastscratch/myscratch/shicks1/alsf-filbin/salmon_files/
# cd /fastscratch/myscratch/akuo/alsf-filbin/salmon_files/

# create salmon index (this process takes ~3 hours)
salmon index -t gencode.v32.preandmrna.fa.gz -i gencode.v32_salmon-index-v1.0.0 --threads 4
```

## Running salmon 

See the `scripts/run-salmon.sh` file in the terminal. 

## Creating SummarizedExperiment object

```{r}
# list tumor names
tumor_names <- list.files(here("sample_data"))[
                  !grepl("*.txt", list.files(here("sample_data")))]

unique_sf_paths <- NULL
for(tum in tumor_names){
  ids <- list.files(paste(path_dir, tum, sep="/"))
  ids <- unique(stringr::str_sub(ids, end=-13))
  ids <- paste(path_dir, "salmon_quants", paste0(ids, "_quant/quant.sf"), sep="/")
  unique_sf_paths <- c(unique_sf_paths, ids)
}

unique_sf_ids <- NULL
for(tum in tumor_names){
  ids <- list.files(paste(path_dir, tum, sep="/"))
  ids <- unique(stringr::str_sub(ids, end=-13))
  unique_sf_ids <- c(unique_sf_ids, ids)
}

coldata <- data.frame(files = unique_sf_paths, names = unique_sf_ids)

```

tximeta couldn't automatically detect the transcriptome, so we might have to create our own. The code chunk below was my failed attempt to create one.

Source: https://bioconductor.org/packages/release/bioc/vignettes/tximeta/inst/doc/tximeta.html#linked_transcriptomes

```{r}
library(tximeta)
dir = "/users/akuo/pre_mRNA/data/reference/genomes/hsapiens/GENCODE/release_32"
fasta_path = file.path(dir, "gencode.v32.preandmrna.fa.gz")
gtf_path = file.path(dir, "gencode.v32.annotation.gtf.gz") # May need to generate another gtf file
index_dir = file.path(dir, "gencode.v32_salmon-index-v1.0.0")

tmp <- tempdir()
#jsonFile <- file.path(tmp, "tmp.json")
makeLinkedTxome(indexDir=index_dir,
                source="GENCODE", organism="Homo sapiens",
                release="32", genome="GRCh38",
                fasta=fasta_path, gtf=gtf_path,
                write=FALSE)
```

```{r}
library(tximeta)
se <- tximeta(coldata[1:96,])
```


# Quality control 

## Explore SummarizedExperiment object

```{r}
suppressPackageStartupMessages(library(SummarizedExperiment))
colData(se)
assayNames(se)
rowRanges(se)
```

```{r}
dat <- assay(se, "counts")
hist(colSums(dat))
```