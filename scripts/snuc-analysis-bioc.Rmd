---
title: qc and analysis of single nuc-seq data (alsf-filbin)
author: Stephanie Hicks and Albert Kuo
output: 
  html_document:
    code_folding: "hide"
    toc: TRUE
    toc_float: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```

```{bash eval = F}
# Commands to start an interactive session on the JHPCE cluster
qrsh -l mem_free=20G,h_vmem=20G
module load conda_R
cd /fastscratch/myscratch/akuo/alsf-filbin
R
```

```{r eval = F}
library(here)
dataset = "mrna" # options = "premrna_mrna", "mrna", or "premrna"
```

# Create SummarizedExperiment object

First, we create a table with information about where each file (quantified counts from salmon) is. 
This will be used to create a `SummarizedExperiment` object.

```{r eval = F}
# list tumor names
tumor_names <- list.files(here("sample_data"))[
                  !grepl("*.txt", list.files(here("sample_data")))]

unique_sf_paths <- NULL
for(tum in tumor_names){
  ids <- list.files(here("sample_data", tum))
  ids <- unique(stringr::str_sub(ids, end=-13))
  ids <- here("salmon_quants", paste0(ids, "_quant"), "quant.sf")
  unique_sf_paths <- c(unique_sf_paths, ids)
}

unique_sf_ids <- NULL
for(tum in tumor_names){
  ids <- list.files(here("sample_data", tum))
  ids <- unique(stringr::str_sub(ids, end=-13))
  unique_sf_ids <- c(unique_sf_ids, ids)
}

coldata <- data.frame(files = unique_sf_paths, names = unique_sf_ids)
```

We also need to use the linkedTxome object to use `tximeta` properly, i.e. `rowRanges(se)` won't be `NULL` and tximeta will be able to match the transcripts to the genes for us. **Note: still doesn't work**

```{r eval = F}
suppressPackageStartupMessages({
  library(tximeta)
  library(BiocFileCache)
})

# check if linkedTxome is already in the cache
bfcloc <- getTximetaBFC()
bfc <- BiocFileCache(bfcloc)
bfcinfo(bfc)

# if not, load linkedTxome json file
json_file <- here("salmon_files", "gencode.v32_salmon-index-v1.0.0.json")
loadLinkedTxome(json_file)
```

The only way I've figured out how to make this work for now is with `skipMeta = TRUE`.

```{r eval = F}
se_file_name = here("salmon_quants", paste0("se_", dataset, ".rds"))

# coldata = coldata[1:2, ] # for testing
if(!file.exists(se_file_name)){
  # Create SummarizedExperiment object
  se <- tximeta(coldata, skipMeta = TRUE) # Takes a few minutes, file size = 597 MB
  # se <- tximeta(coldata) # run this line if you used mRNA transcripts in your index only, it will automatically detect the right transcriptome
  # se <- tximeta(coldata, ignoreAfterBar = TRUE)
  saveRDS(se, se_file_name)
} else {
  se = readRDS(se_file_name) # Takes a couple of seconds
}
```

```{r eval = F}
suppressPackageStartupMessages({
  library(SummarizedExperiment)
  library(DESeq2)
})

colData(se)
assayNames(se)
rowRanges(se)

dat = assay(se, "counts")
```

# Create SingleCellExperiment object

A SingleCellExperiment class is derived from the SummarizedExperiment class. The most important change is the addition of a new slot called `reducedDims`. Read more [here](https://osca.bioconductor.org/data-infrastructure.html#a-brief-recap-from-se-to-sce).

```{r eval = F}
# BiocManager::install('SingleCellExperiment')
library(SingleCellExperiment)
```

```{r eval = F}
sce = SingleCellExperiment(assays = list(counts = dat))

# you can access counts by assay(sce, "counts") or counts(sce)
# you can add a new entry to assays slot by assay(sce, "counts_new") = dat_new
```

## Quality Control

There are a couple of [QC metrics](https://osca.bioconductor.org/quality-control.html#choice-of-qc-metrics) to identify low-quality cells:

1. Using counts, i.e. cells with (a) a small library size (total sum of counts) `low_lib_size` or (b) few expressed endogeneous genes (nonzero counts for those genes) `low_n_features`
2. Using "spike-in transcripts", i.e. any enrichment of spike-in transcripts (higher proportion) 
3. Using the mitochondrial genome, i.e. any enrichment of reads in the mitochondrial genome is indicative of loss of cytoplasmic RNA

I will only do (1) for now.

```{r eval = F}
library(scater)

# Compute quality control metrics:
# sum is the total count for each cell
# detected contains the number of detected genes (actually transcripts for our data)
df = perCellQCMetrics(sce)
df

# Find outliers with low library sizes (LibSize) and few detected features (n_features)
reasons = quickPerCellQC(df) # DataFrame of logical values
colSums(as.matrix(reasons))

# Discard outliers
filtered = sce[, !reasons$discard] 
dat_filtered = counts(filtered) # 226608 x 518 for mrna, 221988 x 546 for premrna

filtered_file_name = here("salmon_quants", paste0("dat_filtered_", dataset, ".rds"))
saveRDS(dat_filtered, filtered_file_name)
```

Diagnostic plots: https://osca.bioconductor.org/quality-control.html#quality-control-plots 

# Transform read counts

```{r}
library(here)
library(ggplot2)
library(dplyr)
library(tidyr)
library(SingleCellExperiment)
dataset = "mrna"
```

## Convert read counts to pseudo-UMIs

Run `compute-mle.sh` to get mle sig ("shape") parameter first. There will be a parameter for every cell. It will take about 30 minutes to an hour.

```{r eval = F}
# Load filtered counts
filtered_file_name = here("salmon_quants", paste0("dat_filtered_", dataset, ".rds"))
if(file.exists(filtered_file_name)){
  dat_filtered = readRDS(filtered_file_name)
}

# Read in mle parameters
mle_file_names = list.files(here("mle_results"), full.names = TRUE)
mle_results = lapply(mle_file_names, readRDS)
sig_vec = sapply(mle_results, function(r) r["sig"])
mu_vec = sapply(mle_results, function(r) r["mu"])

# Plot sig ("shape") distribution
ggplot(tibble(sig = sig_vec), aes(x = sig)) +
  geom_histogram(bins = 30) +
  labs(title = "Distribution of sig parameter",
       x = "sig",
       y = "Number of cells")
```

```{r}
getMode <- function(x){
  keys <- unique(x)
  keys[which.max(tabulate(match(x, keys)))]
}

source(here("scripts", "quminorm.R"))
# Convert to pseudo-UMIs
umi_file_name = here("salmon_quants", paste0("dat_umi_", dataset, ".rds"))
if(file.exists(umi_file_name)){
  dat_umi = readRDS(umi_file_name)
} else {
  dat_umi = quminorm_matrix(dat_filtered, shape = getMode(sig_vec)) # Takes several minutes (20~30 min). In the paper, they use the mode.
  dat_umi = dat_umi[!(rowSums(dat_umi) == 0), ] # Remove transcripts with all zeros
  saveRDS(dat_umi, umi_file_name)
}
```

## Aggregate counts at gene level

```{r eval = F}
umi_file_name = here("salmon_quants", paste0("dat_umi_", dataset, ".rds"))
dat_umi = readRDS(umi_file_name)

# Original data by transcript
dim(dat_umi) #  x  for mRNA, 173926 x 546 for premRNA

if(dataset == "mrna"){
  row_ranges = rowRanges(se)
  genes = unlist(elementMetadata(row_ranges)$gene_id)
  dat = rowsum(dat_umi, group = genes, reorder = FALSE)
  dim(dat) # 
} else if(dataset == "premrna") {
  se_mrna = readRDS(here("salmon_quants", paste0("se_mrna.rds")))
  transcripts_mrna = rownames(assay(se_mrna, "counts"))
  row_ranges = rowRanges(se_mrna)
  genes = unlist(elementMetadata(row_ranges)$gene_id)
  mrna_gene_matching_dt = tibble(transcript = transcripts_mrna,
                                 genes)
  
  # Get genes for every premrna transcript
  # Note: 208 premRNA transcripts did not have corresponding mRNA transcripts
  transcripts_premrna = rownames(dat_umi)
  transcripts_premrna_converted = gsub(".{8}$", "" , transcripts_premrna)
  premrna_gene_matching_dt = left_join(tibble(transcript = transcripts_premrna_converted),
                                       mrna_gene_matching_dt, by = "transcript")
  
  dat = rowsum(dat_umi, group = premrna_gene_matching_dt$genes, reorder = FALSE)
  dim(dat) # 50477 x 546
}

gene_file_name = here("salmon_quants", paste0("dat_gene_", dataset, ".rds"))
saveRDS(dat_gene, gene_file_name)
```

# Exploratory Plots

```{r}
library(here)
library(ggplot2)
library(dplyr)
library(tidyr)
dataset = "mrna" # options = "premrna_mrna", "mrna", or "premrna"

dat_prem = readRDS(here("salmon_quants", "dat_gene_premrna.rds"))
dat_mrna = readRDS(here("salmon_quants", "dat_gene_mrna.rds"))
```

## Compare pre-mRNA vs mRNA counts

```{r}

```



### Distribution of pre-mRNA

First, I make all the column sums the same by scaling. The count in row $i$ and column $j$ is transformed as $x_{ij} = x_{ij}*\sum_i x_{ij}/median_j(\sum_i x_{ij})$. 

```{r pre-mRNA_distribution}
summary(colSums(dat_prem))

# Apply transformation
n = round(median(colSums(dat_prem)))
dat_prem = apply(dat_prem, MARGIN = 2, function(x) x*n/sum(x))

summary(colSums(dat_prem))
```

I plot the mean and variance for every row (transcript). Under a poisson distribution, they should be the same.

```{r}
plot_meanvar = function(dat_sub){
  # estimate lambdas and variances for every transcript
  means = rowMeans(dat_sub)
  vars = apply(dat_sub, MARGIN = 1, var)
  
  # variance = mean under Poisson distribution
  tibble(means, vars) %>%
    ggplot(aes(x = log(means), y = log(vars))) +
    geom_point(alpha = 0.4) +
    geom_abline(intercept = 0, slope = 1)
}
```

```{r}
plot_meanvar(dat_prem) +
  labs(title = "pre-mRNA")
```

I first compute the average expression for every row (x-axis) $\hat{\mu}_i$ and the empirical $P(X_i=0)$, which is the probability that for a given transcript $i$, the count is 0. 

I then compute what $P(X_i=0)$ would be under the model assumptions of binomial or poisson, using parameters estimated from the data. In particular, for a $Binom(n, p_i)$, $n$ is the median number of total counts of cells and $p_i$ is the mean proportion of counts that were in gene $i$.

```{r}
# Function to plot P(X_i = 0) against average expression level mu_i
plot_prob = function(dat_sub){
  n = round(median(colSums(dat_sub)))
  means = rowMeans(dat_sub)
  vars = apply(dat_sub, MARGIN = 1, var)
  
  # empirical P(X_i = 0)
  emp_probs_0 = apply(dat_sub, MARGIN = 1, function(r) sum(r==0)/ncol(dat_sub))
  plot_dt = tibble(means, emp_probs_0)
  
  emp_props = rowMeans(dat_sub/colSums(dat_sub))
  # Model P(X_i = 0) under Binomial
  binom_probs_0 = dbinom(x = 0, size = n, prob = emp_props)
  # Model P(X_i = 0) under Poisson
  poiss_probs_0 = dpois(x = 0, lambda = n*emp_props)
  # Model P(X_i = 0) under Negative Binomial
  # Estimate size/dispersion parameter
  model = lm(vars ~ 1*means + I(means^2) + 0, tibble(means, vars))
  phi = 1/coef(model)["I(means^2)"]
  nbinom_probs_0 = dnbinom(x = 0, size = phi, mu = n*emp_props) 
  
  # Tibble for plot
  plot_lines_dt = tibble(means = means,
                         binomial = binom_probs_0,
                         poisson = poiss_probs_0,
                         nbinomial = nbinom_probs_0) %>%
    pivot_longer(-means, names_to = "model", values_to = "probs_0")
  
  # Plot
  plt = plot_lines_dt %>%
    ggplot(aes(x = log(means), y = probs_0)) +
    geom_point(data = plot_dt, aes(x = log(means), y = emp_probs_0), alpha = 0.4) + # Add data points
    geom_line(aes(color = model),
              size = 1.5) + # Add lines for models
    labs(x = "Average expression level log(E(X_i))",
         y = "P(X_i = 0)") +
    theme(text = element_text(size = 15))
  
  # Return object
  out = list(plot = plt,
             lines_dt = plot_lines_dt)
  return(out)
}
```

```{r}
# Plot P(X_i = 0) against average expression level
prob_out_prem = plot_prob(dat_prem)
prob_out_prem$plot +
  labs(title = "pre-mRNA")
```

```{r eval = F}
# qqplot for first row
qprobs = seq(0.01, 0.99, by = 0.01)
plot(quantile(rpois(1000, lambda = lambdas[1]), qprobs),
     quantile(dat_prem[,1], probs = qprobs))
```

### Distribution of mRNA

```{r mRNA_distribution}
summary(colSums(dat_mrna))

# Apply transformation
n = round(median(colSums(dat_mrna)))
dat_mrna = apply(dat_mrna, MARGIN = 2, function(x) x*n/sum(x))

summary(colSums(dat_mrna))
```

```{r}
# Plot mean against variance
plot_meanvar(dat_mrna) +
  labs(title = "mRNA")
```

```{r}
# Plot P(X_i = 0) against average expression level
prob_out_mrna = plot_prob(dat_mrna)
prob_out_mrna$plot +
  labs(title = "mRNA")
```


## PCA

```{r}
library(scran)
library(BiocSingular)
# library(factoextra)
library(tictoc)
library(glmpca)
```

```{r}
# Cells in each cluster are normalized separately
clust = quickCluster(dat_umi)
table(clust)
deconv = computeSumFactors(dat_umi, cluster = clust)
```

```{r}
X = dat_umi %>%
  as.matrix() %>%
  sweep(., 2, deconv, "/") %>% # Divide by library size
  t()
X = log2(X + 1) # Apply log transformation

# Remove columns (transcripts) with zero variance
nonzero_var_cols = which(apply(X, 2, var) != 0)
X = X[, nonzero_var_cols]
```

```{r pca}
# Run approximate PCA (8 seconds)
tic("approx PCA")
pc = runPCA(X, rank = 5, BSPARAM = IrlbaParam())
toc()

# set.seed(1)
# Run random PCA (2 minutes)
# tic("random PCA")
# pc = runPCA(X, rank = 5, BSPARAM = RandomParam())
# toc()

# Run PCA with prcomp (~10 minutes)
# pc = prcomp(X, center = T, scale = F)
# % variance explained by each PC
# fviz_eig(pc)
```

```{r}
# Plot PC
data.frame(PC1 = pc$x[,1], PC2 = pc$x[,2]) %>%
  ggplot(aes(PC1, PC2)) +
  geom_point(alpha = 0.5) +
  theme_bw()

data.frame(PC1 = pc$x[,1], PC3 = pc$x[,3]) %>%
  ggplot(aes(PC1, PC3)) +
  geom_point(alpha = 0.5) +
  theme_bw()

data.frame(PC2 = pc$x[,2], PC3 = pc$x[,3]) %>%
  ggplot(aes(PC2, PC3)) +
  geom_point(alpha = 0.5) +
  theme_bw()

data.frame(PC4 = pc$x[,4], PC5 = pc$x[,5]) %>%
  ggplot(aes(PC4, PC5)) +
  geom_point(alpha = 0.5) +
  theme_bw()
```

### GLM-PCA

```{r eval = F}
# Takes a long time, may want to try on cluster
tic("glm PCA")
glmpca(dat_umi %>% as.matrix(), L = 5, fam = c("poi"))
toc()
```

